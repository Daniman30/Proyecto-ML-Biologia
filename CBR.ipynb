{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from typing import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(image_folder, label_folder, output_json):\n",
    "    \"\"\"Procesa todas las imágenes en la carpeta y extrae características de cada espora.\"\"\"\n",
    "    all_features = {}\n",
    "\n",
    "    # Obtener lista de archivos en ambas carpetas\n",
    "    image_files = {os.path.splitext(f)[0]: os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "    label_files = {os.path.splitext(f)[0]: os.path.join(label_folder, f) for f in os.listdir(label_folder) if f.endswith('.txt')}\n",
    "\n",
    "    # Procesar solo los archivos que tienen imagen y label correspondiente\n",
    "    common_files = image_files.keys() & label_files.keys()\n",
    "\n",
    "    # Cargar el archivo YAML\n",
    "    try:\n",
    "        with open(\".\\\\Imagenes\\\\dataset\\\\data.yaml\", \"r\") as file:\n",
    "            data = yaml.safe_load(file)  # Carga el contenido del YAML\n",
    "    except:\n",
    "        with open(\"../Imagenes/dataset/data.yaml\", \"r\") as file:\n",
    "            data = yaml.safe_load(file)  # Carga el contenido del YAML\n",
    "\n",
    "    # Extraer la lista de nombres de las clases\n",
    "    class_names = data.get(\"names\", [])  # Si \"names\" no existe, devuelve una lista vacía\n",
    "\n",
    "    for file_name in tqdm(common_files):\n",
    "        image_path = image_files[file_name]\n",
    "        label_path = label_files[file_name]\n",
    "\n",
    "        # print(f\"Procesando: {image_path} con {label_path}\")\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: No se pudo cargar la imagen {image_path}\")\n",
    "            continue\n",
    "\n",
    "        bboxes = load_labels(label_path, image.shape)\n",
    "\n",
    "        for i, (class_id, x_min, y_min, width, height) in enumerate(bboxes):\n",
    "            roi = image[y_min:y_min+height, x_min:x_min+width]\n",
    "\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            features = extract_features(roi)\n",
    "            # Agregar información del bounding box\n",
    "            espora_id = f\"{file_name}_espora_{i}_class_{class_id}\"\n",
    "            all_features[espora_id] = {\n",
    "                \"bounding_box\": {\n",
    "                    \"class\": class_names[class_id],\n",
    "                    \"x_min\": x_min,\n",
    "                    \"y_min\": y_min,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height\n",
    "                },\n",
    "                \"features\": features\n",
    "            }\n",
    "\n",
    "    # Guardar en JSON\n",
    "    with open(output_json, \"w\") as json_file:\n",
    "        json.dump(all_features, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_database(json_path):\n",
    "    \"\"\"Carga la base de datos de esporas desde un JSON.\"\"\"\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    except:\n",
    "        try:\n",
    "            image_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\images\"\n",
    "            label_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\labels\"\n",
    "            output_json = \".\\\\spore_features.json\"\n",
    "        except:\n",
    "            image_folder = \"../Imágenes/dataset/train/images\"\n",
    "            label_folder = \"../Imágenes/dataset/train/labels\"\n",
    "            output_json = \"../spore_features.json\"\n",
    "        process_images(image_folder, label_folder, output_json)\n",
    "\n",
    "\n",
    "# Cargar base de datos\n",
    "try:\n",
    "    database = load_database(\"D:\\\\MatCom\\\\4toanno\\\\1er_Semestre\\\\Machine_Learning\\\\Proyecto\\\\CBR_algorithim\\\\spore_features.json\")\n",
    "except:\n",
    "    database = load_database(\"../spore_features.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chi_square_distance(hist1, hist2):\n",
    "    \"\"\"Calcula la distancia Chi-cuadrado entre dos histogramas.\"\"\"\n",
    "    return 0.5 * np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-7))\n",
    "\n",
    "def compare_cases(case1, case2):\n",
    "    \"\"\"Calcula la similitud entre dos esporas usando varias métricas.\"\"\"\n",
    "    \n",
    "    # Comparación de bounding box (penaliza esporas con tamaños muy diferentes)\n",
    "    bbox_diff = abs(case1[\"bounding_box\"][\"width\"] - case2[\"bounding_box\"][\"width\"]) + \\\n",
    "                abs(case1[\"bounding_box\"][\"height\"] - case2[\"bounding_box\"][\"height\"])\n",
    "\n",
    "    # Comparación de estadísticas básicas (media, desviación estándar, valores mínimo y máximo)\n",
    "    stats1 = np.array([case1[\"features\"][\"stats\"][\"mean_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"std_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"min_gray\"], \n",
    "                        case1[\"features\"][\"stats\"][\"max_gray\"]])\n",
    "    stats2 = np.array([case2[\"features\"][\"stats\"][\"mean_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"std_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"min_gray\"], \n",
    "                        case2[\"features\"][\"stats\"][\"max_gray\"]])\n",
    "    stats_distance = euclidean(stats1, stats2)\n",
    "\n",
    "    # Comparación de histogramas de color en HSV\n",
    "    hist1 = np.concatenate(case1[\"features\"][\"color_features\"][\"hist_hsv\"])\n",
    "    hist2 = np.concatenate(case2[\"features\"][\"color_features\"][\"hist_hsv\"])\n",
    "    hist_similarity = cosine(hist1, hist2)\n",
    "\n",
    "    # Comparación de características de textura (GLCM)\n",
    "    texture1 = np.array([\n",
    "        case1[\"features\"][\"texture_features\"][\"contrast\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"homogeneity\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"energy\"],\n",
    "        case1[\"features\"][\"texture_features\"][\"correlation\"]\n",
    "    ])\n",
    "    texture2 = np.array([\n",
    "        case2[\"features\"][\"texture_features\"][\"contrast\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"homogeneity\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"energy\"],\n",
    "        case2[\"features\"][\"texture_features\"][\"correlation\"]\n",
    "    ])\n",
    "    texture_distance = euclidean(texture1, texture2)\n",
    "\n",
    "    # Comparación de momentos de Hu (medida de similitud basada en distancia euclidiana)\n",
    "    hu1 = np.array(case1[\"features\"][\"stats\"][\"hu_moments\"])\n",
    "    hu2 = np.array(case2[\"features\"][\"stats\"][\"hu_moments\"])\n",
    "    hu_distance = euclidean(hu1, hu2)\n",
    "\n",
    "    # Comparación de LBP (usando distancia de Chi-cuadrado)\n",
    "    lbp1 = np.array(case1[\"features\"][\"texture_features\"][\"lbp_histogram\"])\n",
    "    lbp2 = np.array(case2[\"features\"][\"texture_features\"][\"lbp_histogram\"])\n",
    "    lbp_distance = chi_square_distance(lbp1, lbp2)\n",
    "\n",
    "    # Ponderación de las similitudes\n",
    "    similarity_score = (stats_distance * 0.2) + (hist_similarity * 0.25) + \\\n",
    "                       (texture_distance * 0.2) + (hu_distance * 0.2) + \\\n",
    "                       (lbp_distance * 0.1) + (bbox_diff * 0.05)\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "def find_similar_cases(new_case, database, top_n=5):\n",
    "    \"\"\"Encuentra los casos más similares en la base de datos.\"\"\"\n",
    "    similarities = []\n",
    "\n",
    "    for espora_id, case in database.items():\n",
    "        score = compare_cases(new_case, case)\n",
    "        similarities.append((database[espora_id][\"bounding_box\"][\"class\"], score))\n",
    "\n",
    "    # Ordenar por menor distancia (más similar)\n",
    "    similarities.sort(key=lambda x: x[1])\n",
    "\n",
    "    k_values = similarities[:top_n]\n",
    "    threshold = calculate_dynamic_threshold(database)\n",
    "\n",
    "    # Decisión basada en umbral\n",
    "    if min(k_values) > threshold:\n",
    "        return \"Clasificación manual requerida\"\n",
    "    else:\n",
    "        most_common = Counter(k_values).most_common()\n",
    "        return k_values\n",
    "    \n",
    "def calculate_dynamic_threshold(database):\n",
    "    \"\"\"Calcula un umbral basado en el percentil 90 de las similitudes previas.\"\"\"\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i in range(len(database)):\n",
    "        for j in range(i + 1, len(database)):\n",
    "            similarity_scores.append(compare_cases(database[i], database[j]))\n",
    "\n",
    "    return float(np.percentile(similarity_scores, 90))  # Usa el percentil 90 como umbral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path, image_shape):\n",
    "    \"\"\"Carga los bounding boxes desde un archivo de etiquetas YOLO.\"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    bboxes = []\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        values = line.strip().split()\n",
    "        class_id = int(values[0])\n",
    "        x_center, y_center, width, height = map(float, values[1:])\n",
    "\n",
    "        # Convertir coordenadas normalizadas a píxeles\n",
    "        x_min = int((x_center - width / 2) * w)\n",
    "        y_min = int((y_center - height / 2) * h)\n",
    "        box_width = int(width * w)\n",
    "        box_height = int(height * h)\n",
    "\n",
    "        bboxes.append((class_id, x_min, y_min, box_width, box_height))\n",
    "\n",
    "    return bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    \"\"\"Extrae características de color, textura y estadísticas de una imagen.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Estadísticas básicas\n",
    "    mean_gray =float(np.mean(gray))\n",
    "    std_gray = float(np.std(gray))\n",
    "    min_gray = float(np.min(gray))\n",
    "    max_gray = float(np.max(gray))\n",
    "\n",
    "    # Características de forma (Momentos de Hu)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu_moments = list(cv2.HuMoments(moments).flatten())\n",
    "\n",
    "    # Características de color (media y desviación estándar en RGB)\n",
    "    mean_rgb = list(np.mean(image, axis=(0, 1)).tolist())\n",
    "    std_rgb = list(np.std(image, axis=(0, 1)).tolist())\n",
    "\n",
    "    # Características de color (media y desviación estándar en HSV)\n",
    "    mean_hsv = list(np.mean(hsv, axis=(0, 1)).tolist())\n",
    "    std_hsv = list(np.std(hsv, axis=(0, 1)).tolist())\n",
    "\n",
    "    # Histograma de color en RGB\n",
    "    list_rgb = [cv2.calcHist([image], [i], None, [256], [0, 256]).flatten().tolist() for i in range(3)]\n",
    "    hist_rgb = [list([float(n) for n in h]) for h in list_rgb] # Cantidad de píxeles para cada posible intensidad de color (de 0 a 255).\n",
    "\n",
    "    # Histograma de color en HSV (normalizado)\n",
    "    list_hsv = [cv2.calcHist([hsv], [i], None, [256], [0, 256]).flatten() for i in range(3)]\n",
    "    hist_hsv = [h / h.sum() for h in list_hsv]  # Normalización\n",
    "\n",
    "    # Textura: características GLCM\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "\n",
    "    # Local Binary Pattern (LBP)\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    lbp_hist = lbp_hist.astype(\"float\")\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-7)  # Normalización\n",
    "\n",
    "    return {\n",
    "        \"color_features\": {\n",
    "            \"mean_hsv\": mean_hsv,\n",
    "            \"std_hsv\": std_hsv,\n",
    "            \"hist_hsv\": [h.tolist() for h in hist_hsv]  # Convertir a lista para JSON\n",
    "        },\n",
    "        \"texture_features\": {\n",
    "            \"contrast\": contrast,\n",
    "            \"dissimilarity\": dissimilarity,\n",
    "            \"homogeneity\": homogeneity,\n",
    "            \"energy\": energy,\n",
    "            \"correlation\": correlation,\n",
    "            \"lbp_histogram\": lbp_hist.tolist()\n",
    "        },\n",
    "        \"stats\": {\n",
    "            \"mean_gray\": mean_gray,\n",
    "            \"std_gray\": std_gray,\n",
    "            \"min_gray\": min_gray,\n",
    "            \"max_gray\": max_gray,\n",
    "            \"hu_moments\": hu_moments\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(image):\n",
    "    \"\"\" Segmenta la imagen para detectar esporas. \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "\n",
    "    return bounding_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image,case_database):\n",
    "    \"\"\" Predice el tipo de espora en una imagen usando CBR y aprendizaje automático. \"\"\"\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # 1. Segmentar la imagen\n",
    "    bounding_boxes = segment_image(image)\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        # 2. Extraer características de la espora detectada\n",
    "        x, y, w, h = box\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        features = extract_features(roi)\n",
    "        all_features = {\n",
    "                \"bounding_box\": {\n",
    "                    \"class\": '',\n",
    "                    \"x_min\": x,\n",
    "                    \"y_min\": y,\n",
    "                    \"width\": w,\n",
    "                    \"height\": h\n",
    "                },\n",
    "                \"features\": features\n",
    "            }\n",
    "\n",
    "        # 3. Buscar el caso más similar en la base de datos\n",
    "        best_case = find_similar_cases(all_features, case_database)\n",
    "\n",
    "      \n",
    "\n",
    "    return best_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Imágenes/dataset/valid/images/38_4_jpg.rf.53687af4604024c3102f698c90e2a495.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(valid_image_files[image])\n\u001b[1;32m     25\u001b[0m     image1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(valid_image_files[image])\n\u001b[0;32m---> 26\u001b[0m     resultados \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     # Mostrar resultados\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m resultados:\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(image, case_database)\u001b[0m\n\u001b[1;32m     14\u001b[0m     all_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     16\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: features\n\u001b[1;32m     23\u001b[0m         }\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# 3. Buscar el caso más similar en la base de datos\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     best_case \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_database\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_case\n",
      "Cell \u001b[0;32mIn[7], line 72\u001b[0m, in \u001b[0;36mfind_similar_cases\u001b[0;34m(new_case, database, top_n)\u001b[0m\n\u001b[1;32m     69\u001b[0m similarities\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     71\u001b[0m k_values \u001b[38;5;241m=\u001b[39m similarities[:top_n]\n\u001b[0;32m---> 72\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_dynamic_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Decisión basada en umbral\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(k_values) \u001b[38;5;241m>\u001b[39m threshold:\n",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m, in \u001b[0;36mcalculate_dynamic_threshold\u001b[0;34m(database)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(database)):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(database)):\n\u001b[0;32m---> 87\u001b[0m         similarity_scores\u001b[38;5;241m.\u001b[39mappend(compare_cases(\u001b[43mdatabase\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, database[j]))\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mpercentile(similarity_scores, \u001b[38;5;241m90\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     image_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\images\"\n",
    "#     label_folder = \".\\\\Imágenes\\\\dataset\\\\train\\\\labels\"\n",
    "#     output_json = \".\\\\spore_features.json\"\n",
    "# except:\n",
    "#     image_folder = \"../Imágenes/dataset/train/images\"\n",
    "#     label_folder = \"../Imágenes/dataset/train/labels\"\n",
    "#     output_json = \"../spore_features.json\"\n",
    "# process_images(image_folder, label_folder, output_json)\n",
    "\n",
    "\n",
    "\n",
    "# # Cargar imagen\n",
    "try:\n",
    "    valid_image_folder = \"D:\\\\MatCom\\\\4toanno\\\\1er_Semestre\\\\Machine_Learning\\\\Proyecto\\\\CBR_algorithim\\\\Imagenes\\\\dataset\\\\valid\\\\images\"\n",
    "    valid_image_files = {os.path.splitext(f)[0]: os.path.join(valid_image_folder, f) for f in os.listdir(valid_image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "except:\n",
    "    valid_image_folder = \"../Imágenes/dataset/valid/images\"\n",
    "    valid_image_files = {os.path.splitext(f)[0]: os.path.join(valid_image_folder, f) for f in os.listdir(valid_image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))}\n",
    "\n",
    "\n",
    "# # Ejecutar predicción\n",
    "for image in tqdm(valid_image_files.keys()):\n",
    "    print(valid_image_files[image])\n",
    "    image1 = cv2.imread(valid_image_files[image])\n",
    "    resultados = predict(image1, database)\n",
    "\n",
    "#     # Mostrar resultados\n",
    "    for res in resultados:\n",
    "        print(f\"Espora detectada en {res['bounding_box']} - Tipo: {res['tipo']} (Confianza: {res['confianza']:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
